{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "winnovation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Tw5zNJ8hQaR",
        "outputId": "c0c7c591-fbd4-4081-ca2f-0e0b7f38dc13"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNViC1NneB2N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e7fc047-e301-454a-c246-1db4ac7cc639"
      },
      "source": [
        "%cd \"/content/drive/My Drive/winno_data\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/.shortcut-targets-by-id/165plmCQgCNweKAK91WDFdf2qJ_UPUCcv/winno_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_YiuNrQZA_y"
      },
      "source": [
        "## Preprocessed stuffs\n",
        "not needed now"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOK1j9PNeMbC"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = pd.read_json(\"WLASL_v0.3.json\")\n",
        "data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3iKgkPHnelMj"
      },
      "source": [
        "\n",
        "\n",
        "f = open(\"out.csv\", \"w\")\n",
        "\n",
        "f.write(\"video_id,label\\n\")\n",
        "\n",
        "for index, label in enumerate(data[\"gloss\"]):\n",
        "  for video_obj in data[\"instances\"][index]:\n",
        "    f.write(\"%s,%s\\n\" %(video_obj[\"video_id\"], label))\n",
        "\n",
        "f.close()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "ylEzbqGBe50E",
        "outputId": "d56dabfc-f65f-4858-8d13-dd625bed27af"
      },
      "source": [
        "dat = pd.read_csv(\"out.csv\")\n",
        "dat[\"label\"].value_counts()[:10].plot(kind='bar')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f75cba1d160>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VomcGF_oxUgk",
        "outputId": "1d428700-aab3-420a-fcc2-a177ae689039"
      },
      "source": [
        "list(dat[\"label\"].value_counts()[:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[40, 35, 30, 26, 26, 26, 25, 25, 24, 23]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbJBiZGvj2tu"
      },
      "source": [
        "dat[\"label\"].value_counts().to_csv(\"label_counts.csv\", index=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0AICKpUlMgX"
      },
      "source": [
        "missing = open(\"missing.txt\", \"r\").readlines()\n",
        "missing = [x.strip() for x in missing]\n",
        "\n",
        "f = open(\"out.csv\", \"r\")\n",
        "out = open(\"dataset.csv\", \"w\")\n",
        "out.write(\"video_path,label\\n\")\n",
        "\n",
        "for line in f.readlines()[1:]:\n",
        "  if line.split(',')[0] not in missing:\n",
        "    #out.write(line)\n",
        "    out.write(\"%s,%s\\n\" %('/content/drive/MyDrive/winno_data/videos/' + line.split(',')[0] +'.mp4', line.split(',')[1].strip()))\n",
        "out.close()\n",
        "f.close()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJGxbD0Ihfpd"
      },
      "source": [
        "filter_dat = pd.read_csv(\"out_with_filter.csv\")\n",
        "filter_dat[\"label\"].value_counts().to_csv(\"label_counts_with_filter.csv\", index=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eve0-E2am1Zy",
        "outputId": "dbb2e7af-7a62-44a5-fed0-b4b3691080c9"
      },
      "source": [
        "#!git reset --hard\n",
        "!git pull origin master\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "remote: Enumerating objects: 5, done.\u001b[K\n",
            "remote: Counting objects:  20% (1/5)\u001b[K\rremote: Counting objects:  40% (2/5)\u001b[K\rremote: Counting objects:  60% (3/5)\u001b[K\rremote: Counting objects:  80% (4/5)\u001b[K\rremote: Counting objects: 100% (5/5)\u001b[K\rremote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1/1)\u001b[K\rremote: Compressing objects: 100% (1/1), done.\u001b[K\n",
            "remote: Total 3 (delta 2), reused 3 (delta 2), pack-reused 0\u001b[K\n",
            "Unpacking objects:  33% (1/3)   \rUnpacking objects:  66% (2/3)   \rUnpacking objects: 100% (3/3)   \rUnpacking objects: 100% (3/3), done.\n",
            "From https://github.com/Social-Projects-Club-IIT-BHU/winnovation\n",
            " * branch            master     -> FETCH_HEAD\n",
            "   ed3531c..e8cda7a  master     -> origin/master\n",
            "Updating ed3531c..e8cda7a\n",
            "Fast-forward\n",
            " custom_generator.py | 15 \u001b[32m++++++\u001b[m\u001b[31m---------\u001b[m\n",
            " 1 file changed, 6 insertions(+), 9 deletions(-)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2OBoFMyZR3F"
      },
      "source": [
        "### Start from here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WuTzsrsZyghY"
      },
      "source": [
        "# Data loading and preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Gmna603iWWj",
        "outputId": "53b0344f-cf68-436a-a8a8-216878c6b164"
      },
      "source": [
        "%cd \"winnovation\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/.shortcut-targets-by-id/165plmCQgCNweKAK91WDFdf2qJ_UPUCcv/winno_data/winnovation\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "be7gYrmqPGN9",
        "outputId": "0d3a9992-a27a-491f-beb7-bb051a5e3ca2"
      },
      "source": [
        "#pull changes\n",
        "!git pull origin master"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "remote: Enumerating objects: 5, done.\u001b[K\n",
            "remote: Counting objects:  20% (1/5)\u001b[K\rremote: Counting objects:  40% (2/5)\u001b[K\rremote: Counting objects:  60% (3/5)\u001b[K\rremote: Counting objects:  80% (4/5)\u001b[K\rremote: Counting objects: 100% (5/5)\u001b[K\rremote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1/1)\u001b[K\rremote: Compressing objects: 100% (1/1), done.\u001b[K\n",
            "remote: Total 3 (delta 2), reused 3 (delta 2), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (3/3), done.\n",
            "From https://github.com/Social-Projects-Club-IIT-BHU/winnovation\n",
            " * branch            master     -> FETCH_HEAD\n",
            "   0d080de..5ff02f5  master     -> origin/master\n",
            "Updating 0d080de..5ff02f5\n",
            "Fast-forward\n",
            " custom_generator.py | 2 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " 1 file changed, 1 insertion(+), 1 deletion(-)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHLMplN0ygLs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "4c63d070-95af-48e7-c389-84866d686771"
      },
      "source": [
        "from data_management import Data_preparation\n",
        "from custom_generator import VideoDataGenerator\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "data = pd.read_csv('/content/drive/MyDrive/winno_data/dataset.csv')\n",
        "data.head()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>video_path</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/drive/MyDrive/winno_data/videos/69241...</td>\n",
              "      <td>book</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/drive/MyDrive/winno_data/videos/65225...</td>\n",
              "      <td>book</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/content/drive/MyDrive/winno_data/videos/68011...</td>\n",
              "      <td>book</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/content/drive/MyDrive/winno_data/videos/68012...</td>\n",
              "      <td>book</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/content/drive/MyDrive/winno_data/videos/70212...</td>\n",
              "      <td>book</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          video_path label\n",
              "0  /content/drive/MyDrive/winno_data/videos/69241...  book\n",
              "1  /content/drive/MyDrive/winno_data/videos/65225...  book\n",
              "2  /content/drive/MyDrive/winno_data/videos/68011...  book\n",
              "3  /content/drive/MyDrive/winno_data/videos/68012...  book\n",
              "4  /content/drive/MyDrive/winno_data/videos/70212...  book"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "id": "V9_F3O7WzR3_",
        "outputId": "e21b737e-a161-4dcc-9258-dec5d48486ba"
      },
      "source": [
        "preparator = Data_preparation(data_df = data, top_labels = 5)\n",
        "preparator.folder_div(folder_path = 'Dataset5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['book', 'drink', 'computer', 'before', 'chair']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "FileExistsError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-0e514ba2b99e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpreparator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mData_preparation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpreparator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfolder_div\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Dataset5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/drive/.shortcut-targets-by-id/165plmCQgCNweKAK91WDFdf2qJ_UPUCcv/winno_data/winnovation/data_management.py\u001b[0m in \u001b[0;36mfolder_div\u001b[0;34m(self, folder_path)\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_division_paths\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_individual_folder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfolder_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_individual_folder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfolder_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0;34m'valid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_individual_folder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfolder_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/.shortcut-targets-by-id/165plmCQgCNweKAK91WDFdf2qJ_UPUCcv/winno_data/winnovation/data_management.py\u001b[0m in \u001b[0;36m_set_individual_folder\u001b[0;34m(self, data, parent_dir, name)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0mdest_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdest_folder\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# making directory for each particular video\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_videowriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdest_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/os.py\u001b[0m in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m         \u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;31m# Cannot rely on checking for EEXIST, since the operating system\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: 'Dataset5/train/book/69241'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_DalX563_im"
      },
      "source": [
        "gen = VideoDataGenerator(base_path = \"/content/drive/MyDrive/winno_data/winnovation/Dataset5\", \n",
        "                         temporal_length = 6, temporal_stride = 2, labels = 5, shape = (128,128))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSCJclwY7bkX"
      },
      "source": [
        "gen.csv_maker() # making the csv files related to all the videos"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2EzAVo45PD2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2ee81e0-7139-4656-d65a-d6cc5aed78a0"
      },
      "source": [
        "train_data = gen.load_samples(data_cat = 'train', Bin = True)\n",
        "val_data = gen.load_samples(data_cat = 'valid',  Bin = True)\n",
        "test_data = gen.load_samples(data_cat = 'test',  Bin = True)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "num of samples from vid seq-book_69241.csv: 35\n",
            "num of samples from vid seq-book_65225.csv: 28\n",
            "num of samples from vid seq-book_68011.csv: 25\n",
            "num of samples from vid seq-book_68012.csv: 54\n",
            "num of samples from vid seq-book_70212.csv: 48\n",
            "num of samples from vid seq-book_70266.csv: 58\n",
            "num of samples from vid seq-book_07085.csv: 53\n",
            "num of samples from vid seq-book_07086.csv: 57\n",
            "num of samples from vid seq-book_07087.csv: 45\n",
            "num of samples from vid seq-book_07069.csv: 13\n",
            "num of samples from vid seq-book_07088.csv: 49\n",
            "num of samples from vid seq-book_07089.csv: 43\n",
            "num of samples from vid seq-book_07090.csv: 54\n",
            "num of samples from vid seq-book_07091.csv: 42\n",
            "num of samples from vid seq-book_07092.csv: 44\n",
            "num of samples from vid seq-book_07093.csv: 48\n",
            "num of samples from vid seq-book_07068.csv: 31\n",
            "num of samples from vid seq-book_07094.csv: 50\n",
            "num of samples from vid seq-book_07095.csv: 48\n",
            "num of samples from vid seq-book_07096.csv: 46\n",
            "num of samples from vid seq-book_07097.csv: 35\n",
            "num of samples from vid seq-book_07070.csv: 41\n",
            "num of samples from vid seq-book_07098.csv: 71\n",
            "num of samples from vid seq-book_07099.csv: 41\n",
            "num of samples from vid seq-book_07071.csv: 8\n",
            "num of samples from vid seq-book_07072.csv: 7\n",
            "num of samples from vid seq-book_07073.csv: 14\n",
            "num of samples from vid seq-drink_69302.csv: 36\n",
            "num of samples from vid seq-drink_65539.csv: 20\n",
            "num of samples from vid seq-drink_70173.csv: 59\n",
            "num of samples from vid seq-drink_68042.csv: 42\n",
            "num of samples from vid seq-drink_68041.csv: 42\n",
            "num of samples from vid seq-drink_17725.csv: 32\n",
            "num of samples from vid seq-drink_17726.csv: 73\n",
            "num of samples from vid seq-drink_17727.csv: 46\n",
            "num of samples from vid seq-drink_17728.csv: 31\n",
            "num of samples from vid seq-drink_17710.csv: 32\n",
            "num of samples from vid seq-drink_17729.csv: 33\n",
            "num of samples from vid seq-drink_17730.csv: 38\n",
            "num of samples from vid seq-drink_17731.csv: 34\n",
            "num of samples from vid seq-drink_17732.csv: 30\n",
            "num of samples from vid seq-drink_17733.csv: 44\n",
            "num of samples from vid seq-drink_65540.csv: 21\n",
            "num of samples from vid seq-drink_17734.csv: 42\n",
            "num of samples from vid seq-drink_17711.csv: 38\n",
            "num of samples from vid seq-drink_17712.csv: 19\n",
            "num of samples from vid seq-drink_17713.csv: 43\n",
            "num of samples from vid seq-drink_17714.csv: 30\n",
            "num of samples from vid seq-drink_17715.csv: 30\n",
            "num of samples from vid seq-drink_17716.csv: 31\n",
            "num of samples from vid seq-computer_12306.csv: 28\n",
            "num of samples from vid seq-computer_68028.csv: 42\n",
            "num of samples from vid seq-computer_12328.csv: 42\n",
            "num of samples from vid seq-computer_12329.csv: 58\n",
            "num of samples from vid seq-computer_12330.csv: 49\n",
            "num of samples from vid seq-computer_12312.csv: 48\n",
            "num of samples from vid seq-computer_12331.csv: 37\n",
            "num of samples from vid seq-computer_12332.csv: 43\n",
            "num of samples from vid seq-computer_12333.csv: 49\n",
            "num of samples from vid seq-computer_12335.csv: 36\n",
            "num of samples from vid seq-computer_12336.csv: 43\n",
            "num of samples from vid seq-computer_12311.csv: 34\n",
            "num of samples from vid seq-computer_12337.csv: 42\n",
            "num of samples from vid seq-computer_12338.csv: 51\n",
            "num of samples from vid seq-computer_12313.csv: 38\n",
            "num of samples from vid seq-computer_12314.csv: 19\n",
            "num of samples from vid seq-computer_12315.csv: 26\n",
            "num of samples from vid seq-computer_12316.csv: 19\n",
            "num of samples from vid seq-computer_12317.csv: 24\n",
            "num of samples from vid seq-computer_12318.csv: 20\n",
            "num of samples from vid seq-before_05724.csv: 21\n",
            "num of samples from vid seq-before_70348.csv: 46\n",
            "num of samples from vid seq-before_68007.csv: 49\n",
            "num of samples from vid seq-before_05744.csv: 31\n",
            "num of samples from vid seq-before_05746.csv: 22\n",
            "num of samples from vid seq-before_05728.csv: 11\n",
            "num of samples from vid seq-before_05747.csv: 36\n",
            "num of samples from vid seq-before_05748.csv: 40\n",
            "num of samples from vid seq-before_05749.csv: 43\n",
            "num of samples from vid seq-before_05750.csv: 48\n",
            "num of samples from vid seq-before_05729.csv: 24\n",
            "num of samples from vid seq-before_05730.csv: 13\n",
            "num of samples from vid seq-before_65167.csv: 27\n",
            "num of samples from vid seq-before_05731.csv: 20\n",
            "num of samples from vid seq-before_05732.csv: 41\n",
            "num of samples from vid seq-before_05733.csv: 52\n",
            "num of samples from vid seq-before_05734.csv: 38\n",
            "num of samples from vid seq-before_05735.csv: 30\n",
            "num of samples from vid seq-chair_09847.csv: 28\n",
            "num of samples from vid seq-chair_70230.csv: 63\n",
            "num of samples from vid seq-chair_70263.csv: 57\n",
            "num of samples from vid seq-chair_68019.csv: 25\n",
            "num of samples from vid seq-chair_09865.csv: 65\n",
            "num of samples from vid seq-chair_09866.csv: 45\n",
            "num of samples from vid seq-chair_09848.csv: 46\n",
            "num of samples from vid seq-chair_09867.csv: 53\n",
            "num of samples from vid seq-chair_09869.csv: 44\n",
            "num of samples from vid seq-chair_09849.csv: 38\n",
            "num of samples from vid seq-chair_09850.csv: 13\n",
            "num of samples from vid seq-chair_09851.csv: 44\n",
            "num of samples from vid seq-chair_65328.csv: 27\n",
            "num of samples from vid seq-chair_09853.csv: 9\n",
            "num of samples from vid seq-chair_09854.csv: 13\n",
            "num of samples from vid seq-chair_09855.csv: 44\n",
            "num of samples from vid seq-chair_09856.csv: 33\n",
            "the exception:  \n",
            "end of file generator\n",
            "num of samples from vid seq-book_67424.csv: 17\n",
            "num of samples from vid seq-book_07074.csv: 17\n",
            "num of samples from vid seq-book_07075.csv: 39\n",
            "num of samples from vid seq-book_07076.csv: 51\n",
            "num of samples from vid seq-book_07077.csv: 56\n",
            "num of samples from vid seq-book_07078.csv: 44\n",
            "num of samples from vid seq-book_07079.csv: 52\n",
            "num of samples from vid seq-drink_17717.csv: 24\n",
            "num of samples from vid seq-drink_17718.csv: 32\n",
            "num of samples from vid seq-drink_17709.csv: 50\n",
            "num of samples from vid seq-drink_67594.csv: 19\n",
            "num of samples from vid seq-drink_17719.csv: 26\n",
            "num of samples from vid seq-computer_12319.csv: 18\n",
            "num of samples from vid seq-computer_12320.csv: 49\n",
            "num of samples from vid seq-computer_67519.csv: 19\n",
            "num of samples from vid seq-computer_12321.csv: 30\n",
            "num of samples from vid seq-computer_12322.csv: 29\n",
            "num of samples from vid seq-before_05736.csv: 4\n",
            "num of samples from vid seq-before_05727.csv: 41\n",
            "num of samples from vid seq-before_05737.csv: 30\n",
            "num of samples from vid seq-before_05739.csv: 23\n",
            "num of samples from vid seq-chair_67483.csv: 13\n",
            "num of samples from vid seq-chair_09857.csv: 58\n",
            "num of samples from vid seq-chair_09858.csv: 54\n",
            "num of samples from vid seq-chair_09859.csv: 55\n",
            "the exception:  \n",
            "end of file generator\n",
            "num of samples from vid seq-book_07080.csv: 59\n",
            "num of samples from vid seq-book_07081.csv: 42\n",
            "num of samples from vid seq-book_07082.csv: 46\n",
            "num of samples from vid seq-book_07083.csv: 55\n",
            "num of samples from vid seq-book_07084.csv: 45\n",
            "num of samples from vid seq-drink_17720.csv: 18\n",
            "num of samples from vid seq-drink_17721.csv: 22\n",
            "num of samples from vid seq-drink_17722.csv: 22\n",
            "num of samples from vid seq-drink_17723.csv: 27\n",
            "num of samples from vid seq-drink_17724.csv: 12\n",
            "num of samples from vid seq-computer_12323.csv: 30\n",
            "num of samples from vid seq-computer_12324.csv: 34\n",
            "num of samples from vid seq-computer_12326.csv: 34\n",
            "num of samples from vid seq-computer_12327.csv: 21\n",
            "num of samples from vid seq-before_05740.csv: 22\n",
            "num of samples from vid seq-before_05741.csv: 13\n",
            "num of samples from vid seq-before_05742.csv: 12\n",
            "num of samples from vid seq-before_05743.csv: 21\n",
            "num of samples from vid seq-chair_09860.csv: 67\n",
            "num of samples from vid seq-chair_09861.csv: 57\n",
            "num of samples from vid seq-chair_09862.csv: 58\n",
            "num of samples from vid seq-chair_09863.csv: 43\n",
            "the exception:  \n",
            "end of file generator\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4c2JLMfgiOm8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b76a954e-8d8f-40aa-ccae-c01f57a2fc6f"
      },
      "source": [
        "train_data[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['/content/drive/MyDrive/winno_data/winnovation/Dataset5/train/book/69241/img9.png',\n",
              "  '/content/drive/MyDrive/winno_data/winnovation/Dataset5/train/book/69241/img22.png',\n",
              "  '/content/drive/MyDrive/winno_data/winnovation/Dataset5/train/book/69241/img29.png',\n",
              "  '/content/drive/MyDrive/winno_data/winnovation/Dataset5/train/book/69241/img38.png',\n",
              "  '/content/drive/MyDrive/winno_data/winnovation/Dataset5/train/book/69241/img49.png',\n",
              "  '/content/drive/MyDrive/winno_data/winnovation/Dataset5/train/book/69241/img66.png'],\n",
              " 'book']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXJ2ZVIgiEDs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57a403f0-d4c2-423b-815c-634c1cdc8ebc"
      },
      "source": [
        "print('no. of instances in train_data', len(train_data))\n",
        "print('no. of instances in validation_data', len(val_data))\n",
        "print('no. of instances in test_data', len(test_data))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "no. of instances in train_data 1343\n",
            "no. of instances in validation_data 292\n",
            "no. of instances in test_data 261\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zPhufvtguQ4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e6b5750-8e77-4ca0-d0cf-937bd75ccaec"
      },
      "source": [
        "#labels = ['book', 'drink', 'computer', 'before', 'chair', 'go', 'clothes', 'who', 'candy', 'help']\n",
        "labels = ['book', 'drink', 'computer', 'before', 'chair']\n",
        "labels_dict = {v:k for k,v in enumerate(labels)}\n",
        "labels_dict"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'before': 3, 'book': 0, 'chair': 4, 'computer': 2, 'drink': 1}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMBdx342mWmN"
      },
      "source": [
        "# Modelling part"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WO_iHJq9Xgzq"
      },
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import ConvLSTM2D, Conv3D, Conv2D, MaxPooling2D, MaxPooling3D, BatchNormalization, Flatten, Dense, LSTM, InputLayer, Dropout, Attention, Input\n",
        "from keras.layers import Layer, Reshape, GlobalAveragePooling2D\n",
        "from keras.applications.mobilenet_v2 import preprocess_input, MobileNetV2\n",
        "#import tensorflow.Module as Module"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7PIzUCEEvMk"
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qhz7IULpqVC7"
      },
      "source": [
        "class MobilePreprocess(keras.layers.Layer):\r\n",
        "  def __init__(self):\r\n",
        "    super(MobilePreprocess, self).__init__()\r\n",
        "  def call(self, inputs):\r\n",
        "    preprocessed_inputs = []\r\n",
        "    if inputs.shape[0] == None :\r\n",
        "      preprocessed_inputs = preprocess_input(inputs[0])\r\n",
        "      preprocessed_inputs = preprocessed_inputs.reshape([1, ] + preprocessed_inputs.shape)\r\n",
        "    else:\r\n",
        "      for i in range(inputs.shape[0]):\r\n",
        "        preprocessed_input = preprocess_input(inputs[i])\r\n",
        "        preprocessed_inputs.append(preprocessed_input)\r\n",
        "      preprocessed_inputs = np.array(preprocessed_inputs)\r\n",
        "    print(preprocessed_inputs.shape)\r\n",
        "    print(preprocessed_inputs)\r\n",
        "    return preprocessed_inputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-GhSd7_jJlK"
      },
      "source": [
        "class MyConv(keras.layers.Layer):\r\n",
        "  def __init__(self, filter1, filter2):\r\n",
        "    super(MyConv, self).__init__()\r\n",
        "    self.conv1 = Sequential([\r\n",
        "                             Conv2D(filter1, (3, 3), activation = 'relu'),\r\n",
        "                             Conv2D(filter2, (3, 3), activation = 'relu'),\r\n",
        "                             MaxPooling2D(pool_size=(3, 3)),\r\n",
        "                             BatchNormalization()\r\n",
        "    ])\r\n",
        "    \r\n",
        "  def call(self, inputs):\r\n",
        "    print(inputs.shape)\r\n",
        "    outs = []\r\n",
        "    r = 1\r\n",
        "    if inputs.shape[0] is not None :\r\n",
        "      r = inputs.shape[0] \r\n",
        "    else :\r\n",
        "      r = 1\r\n",
        "    for i in range(r):\r\n",
        "      inps = inputs[i]\r\n",
        "      out = self.conv1(inps)\r\n",
        "      outs.append(out)\r\n",
        "    outs = tf.convert_to_tensor(outs)\r\n",
        "    \r\n",
        "    \r\n",
        "    return outs\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gnu1UZnLE9iG"
      },
      "source": [
        "class MyDense(keras.layers.Layer):\r\n",
        "  def __init__(self, num_classes):\r\n",
        "    super(MyDense, self).__init__()\r\n",
        "    self.dense = Dense(num_classes, activation= 'softmax')\r\n",
        "    \r\n",
        "  def call(self, inputs):\r\n",
        "    print(inputs.shape)\r\n",
        "    outs = []\r\n",
        "    r = 1\r\n",
        "    if inputs.shape[0] is not None :\r\n",
        "      r = inputs.shape[0] \r\n",
        "    else :\r\n",
        "      r = 1\r\n",
        "    for i in range(r):\r\n",
        "      inps = inputs[i]\r\n",
        "      out = self.dense(inps)\r\n",
        "      outs.append(out)\r\n",
        "    outs = tf.convert_to_tensor(outs)\r\n",
        "    \r\n",
        "    \r\n",
        "    return outs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6iBgg0EvNZ9"
      },
      "source": [
        "class MyMobileNet(keras.layers.Layer):\r\n",
        "  def __init__(self, inp_shape):\r\n",
        "    super(MyMobileNet, self).__init__()\r\n",
        "    self.mob = MobileNetV2(input_shape= inp_shape, include_top= False)\r\n",
        "    self.g_avg = GlobalAveragePooling2D()\r\n",
        "    self.dense = Dense(100, activation= 'relu')\r\n",
        "  def call(self, inputs):\r\n",
        "    outs = []\r\n",
        "    r = 1\r\n",
        "    if inputs.shape[0] is not None :\r\n",
        "      r = inputs.shape[0] \r\n",
        "    else :\r\n",
        "      r = 1\r\n",
        "    for i in range(r):\r\n",
        "      inps = inputs[i]\r\n",
        "      out = self.mob(inps)\r\n",
        "      out = self.g_avg(out)\r\n",
        "      out = self.dense(out)\r\n",
        "      outs.append(out)\r\n",
        "    outs = tf.convert_to_tensor(outs)\r\n",
        "    \r\n",
        "    \r\n",
        "    return outs\r\n",
        "\r\n",
        "mymob = MyMobileNet((224, 224, 3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82cNBiyfd0fM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e64e4d57-f232-4cd8-a187-e304967a7140"
      },
      "source": [
        "def make_model(shape, num_classes=5):\r\n",
        "  model = Sequential([\r\n",
        "                      InputLayer(input_shape= shape),\r\n",
        "                      MyMobileNet((224, 224, 3)),\r\n",
        "                      LSTM(512),\r\n",
        "                      Dense(num_classes, activation= 'softmax')\r\n",
        "  ])\r\n",
        "  model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\r\n",
        "  return model\r\n",
        "\r\n",
        "network = make_model((6, 224, 224, 3))\r\n",
        "network.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "my_mobile_net_18 (MyMobileNe (1, 6, 100)               2386084   \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (1, 512)                  1255424   \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (1, 5)                    2565      \n",
            "=================================================================\n",
            "Total params: 3,644,073\n",
            "Trainable params: 3,609,961\n",
            "Non-trainable params: 34,112\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qFlOwgttqyIX",
        "outputId": "9e871f7a-75ab-4988-cc86-3e876f649595"
      },
      "source": [
        "inps = np.random.uniform(size = (10, 6, 224, 224, 3))\r\n",
        "network(inps)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10, 5), dtype=float32, numpy=\n",
              "array([[0.17918608, 0.20406137, 0.24147812, 0.1547466 , 0.2205278 ],\n",
              "       [0.18303823, 0.2003659 , 0.23982373, 0.15347308, 0.22329904],\n",
              "       [0.17974909, 0.20441422, 0.24261826, 0.15178783, 0.2214306 ],\n",
              "       [0.18226911, 0.20422468, 0.23931707, 0.15062791, 0.22356133],\n",
              "       [0.18028381, 0.20137914, 0.24263151, 0.15082105, 0.22488452],\n",
              "       [0.18345504, 0.19917868, 0.24510916, 0.14915091, 0.22310616],\n",
              "       [0.18093072, 0.2013219 , 0.24364656, 0.14676379, 0.22733702],\n",
              "       [0.17868096, 0.20219633, 0.24395831, 0.15096246, 0.22420193],\n",
              "       [0.18232886, 0.19859987, 0.24406615, 0.14788108, 0.22712398],\n",
              "       [0.18199416, 0.20238087, 0.23991176, 0.15189987, 0.2238133 ]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPoJmSWAJGWj"
      },
      "source": [
        "a = np.array([1, 2])\r\n",
        "a[]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Myc8dyg-d4y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2eaeba0e-2871-4d33-d540-3bf2459be8e8"
      },
      "source": [
        "'''\n",
        "def get_model(num_classes=5):\n",
        "    # Define model\n",
        "    model = Sequential()\n",
        "    model.add(Conv3D(32, kernel_size=(3, 3, 3), input_shape=(\n",
        "        6,64,64,3), padding='same', activation = 'relu'))\n",
        "   # model.add(Conv3D(32, kernel_size=(3, 3, 3), padding='same', activation = 'relu'))\n",
        "    model.add(MaxPooling3D(pool_size=(3, 3, 3), padding='same'))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(BatchNormalization())\n",
        "   # model.add(Conv3D(64, kernel_size=(3, 3, 3), padding='same', activation = 'relu'))\n",
        "    model.add(Conv3D(32, kernel_size=(3, 3, 3), padding='same', activation = 'relu'))\n",
        "    model.add(MaxPooling3D(pool_size=(3, 3, 3), padding='same'))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dense(num_classes, activation = 'softmax'))\n",
        "    model.compile(loss= tf.keras.losses.categorical_crossentropy,\n",
        "                  optimizer=tf.keras.optimizers.Adam(lr = 0.001), metrics=['accuracy'])\n",
        "    model.summary()\n",
        "    #plot_model(model, show_shapes=True,\n",
        "    #           to_file='model.png')\n",
        "    return model\n",
        "model = get_model()\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv3d_2 (Conv3D)            (None, 6, 64, 64, 32)     2624      \n",
            "_________________________________________________________________\n",
            "max_pooling3d_2 (MaxPooling3 (None, 2, 22, 22, 32)     0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 2, 22, 22, 32)     0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 2, 22, 22, 32)     128       \n",
            "_________________________________________________________________\n",
            "conv3d_3 (Conv3D)            (None, 2, 22, 22, 32)     27680     \n",
            "_________________________________________________________________\n",
            "max_pooling3d_3 (MaxPooling3 (None, 1, 8, 8, 32)       0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 1, 8, 8, 32)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 1, 8, 8, 32)       128       \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 256)               524544    \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 256)               1024      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 5)                 1285      \n",
            "=================================================================\n",
            "Total params: 557,413\n",
            "Trainable params: 556,773\n",
            "Non-trainable params: 640\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W51b4C5QwwEi"
      },
      "source": [
        "train_gen = gen.flow(train_data, labels_map_dict = labels_dict, batch_size=10, preprocessing = True)\n",
        "test_gen = gen.flow(test_data, labels_map_dict = labels_dict,  batch_size=10, preprocessing = False)\n",
        "val_gen = gen.flow(val_data, labels_map_dict = labels_dict,  batch_size=10, preprocessing = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lBXY7KJv3B5Q",
        "outputId": "602bb038-a3ae-45e8-de80-fb0315efb8a4"
      },
      "source": [
        "#with tpu_strategy.scope(): # creating the model in the TPUStrategy scope means we will train the model on the TPU\r\n",
        "model = make_model((6, 128, 128, 3))\r\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv3d (Conv3D)              (None, 6, 64, 64, 64)     1792      \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 6, 64, 64, 64)     0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 6, 64, 64, 64)     256       \n",
            "_________________________________________________________________\n",
            "conv3d_1 (Conv3D)            (None, 6, 32, 32, 128)    73856     \n",
            "_________________________________________________________________\n",
            "max_pooling3d (MaxPooling3D) (None, 6, 16, 16, 128)    0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 6, 16, 16, 128)    0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 6, 16, 16, 128)    512       \n",
            "_________________________________________________________________\n",
            "conv_lst_m2d (ConvLSTM2D)    (None, 14, 14, 64)        442624    \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 3136)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               401536    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 5)                 645       \n",
            "=================================================================\n",
            "Total params: 921,221\n",
            "Trainable params: 920,837\n",
            "Non-trainable params: 384\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9IpFgOIAWz_"
      },
      "source": [
        "#from callbacks import XTensorBoard\n",
        "#os.mkdir('weights')\n",
        "callbacks_ = [\n",
        "    tf.keras.callbacks.ModelCheckpoint(filepath = 'weights.hdf5', monitor='val_loss', verbose=2, save_best_only=True, mode='min'),\n",
        "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',\n",
        "                                         factor=0.5,\n",
        "                                         patience=2,\n",
        "                                         cooldown=1,\n",
        "                                         min_lr=0.00001,\n",
        "                                         verbose=1),\n",
        "    tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=4)]\n",
        "   # XTensorBoard(log_dir=str(args.model_dir), **config['tensorboard'])]\n",
        "\n",
        "#model.fit(train_ds, epochs=config['epochs'], callbacks=callbacks,\n",
        "        #  validation_data=val_ds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "id": "qmJyLI4L9keM",
        "outputId": "7bbe9a88-5469-404b-ab91-034fb739a2f8"
      },
      "source": [
        "try:\n",
        "  history = model.fit(train_gen,\n",
        "                    steps_per_epoch = len(train_data)//10, \n",
        "                    validation_data = val_gen,\n",
        "                    batch_size = 10,\n",
        "                    validation_steps = len(val_data)//10,\n",
        "                    epochs = 25, callbacks = callbacks_)\n",
        "except:\n",
        "  model.load_weights('weights.hdf5')\n",
        "  model.save('baselined.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "134/134 [==============================] - ETA: 0s - loss: 1.8495 - accuracy: 0.2134 "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-6789a3178e31>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m                     \u001b[0mvalidation_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                     epochs = 25, callbacks = callbacks_)\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1129\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1130\u001b[0;31m                 steps_per_execution=self._steps_per_execution)\n\u001b[0m\u001b[1;32m   1131\u001b[0m           val_logs = self.evaluate(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[1;32m   1111\u001b[0m         \u001b[0mdistribution_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1112\u001b[0;31m         model=model)\n\u001b[0m\u001b[1;32m   1113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, workers, use_multiprocessing, max_queue_size, model, **kwargs)\u001b[0m\n\u001b[1;32m    780\u001b[0m     \u001b[0mpeek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeek\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 781\u001b[0;31m     \u001b[0mpeek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_tensorlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeek\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    782\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_process_tensorlike\u001b[0;34m(inputs)\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1016\u001b[0;31m   \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_convert_numpy_and_scipy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1017\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_to_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    658\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 659\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m       expand_composites=expand_composites)\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    658\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 659\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m       expand_composites=expand_composites)\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_convert_numpy_and_scipy\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1011\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor_v2_with_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1012\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mscipy_sparse\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mscipy_sparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2_with_dispatch\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m   1404\u001b[0m   return convert_to_tensor_v2(\n\u001b[0;32m-> 1405\u001b[0;31m       value, dtype=dtype, dtype_hint=dtype_hint, name=name)\n\u001b[0m\u001b[1;32m   1406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m   1414\u001b[0m       \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype_hint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1415\u001b[0;31m       as_ref=False)\n\u001b[0m\u001b[1;32m   1416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/profiler/trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1539\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1540\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/tensor_conversion_registry.py\u001b[0m in \u001b[0;36m_default_conversion_function\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mdel\u001b[0m \u001b[0mas_ref\u001b[0m  \u001b[0;31m# Unused.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    264\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 265\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    300\u001b[0m   \u001b[0;34m\"\"\"Implementation of eager constant.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m   \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m     97\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type numpy.ndarray).",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-6789a3178e31>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m                     epochs = 25, callbacks = callbacks_)\n\u001b[1;32m      8\u001b[0m \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'weights.hdf5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'baselined.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, skip_mismatch, options)\u001b[0m\n\u001b[1;32m   2232\u001b[0m             f, self.layers, skip_mismatch=skip_mismatch)\n\u001b[1;32m   2233\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2234\u001b[0;31m         \u001b[0mhdf5_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights_from_hdf5_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2236\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_updated_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/hdf5_format.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group\u001b[0;34m(f, layers)\u001b[0m\n\u001b[1;32m    708\u001b[0m                        str(len(weight_values)) + ' elements.')\n\u001b[1;32m    709\u001b[0m     \u001b[0mweight_value_tuples\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbolic_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m   \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_value_tuples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mbatch_set_value\u001b[0;34m(tuples)\u001b[0m\n\u001b[1;32m   3704\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly_outside_functions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3705\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtuples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3706\u001b[0;31m       \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3707\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3708\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mget_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36massign\u001b[0;34m(self, value, use_locking, name, read_value)\u001b[0m\n\u001b[1;32m    889\u001b[0m             (\"Cannot assign to variable%s due to variable shape %s and value \"\n\u001b[1;32m    890\u001b[0m              \"shape %s are incompatible\") %\n\u001b[0;32m--> 891\u001b[0;31m             (tensor_name, self._shape, value_tensor.shape))\n\u001b[0m\u001b[1;32m    892\u001b[0m       assign_op = gen_resource_variable_ops.assign_variable_op(\n\u001b[1;32m    893\u001b[0m           self.handle, value_tensor, name=name)\n",
            "\u001b[0;31mValueError\u001b[0m: Cannot assign to variable dense/kernel:0 due to variable shape (3136, 128) and value shape (576, 128) are incompatible"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyq6_yY7NT0l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d5f983c-e94f-459a-86c1-e1714fe239a5"
      },
      "source": [
        "#model.load_weights('weights.hdf5')\n",
        "model.save('baselined.pb')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: baselined.pb/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pidbYmJe5C4"
      },
      "source": [
        "model.load_weights('/content/drive/MyDrive/winno_data/winnovation/weights/003-0.690.hdf5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92GI30iLn89C"
      },
      "source": [
        "### Some visualisatons of prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "LEzd0tr7nnjM",
        "outputId": "70fc939e-c69e-4a6f-bf5e-79a522e211d9"
      },
      "source": [
        "plt.subplot(2,1,1)\n",
        "plt.plot(history.history['loss'], color='g')\n",
        "plt.plot(history.history['val_loss'], color='r')\n",
        "plt.title('loss')\n",
        "plt.subplot(2,1,2)\n",
        "plt.plot(history.history['accuracy'], color='g')\n",
        "plt.plot(history.history['val_accuracy'], color ='r' )\n",
        "plt.title('accuracy')\n",
        "plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-e0cb877c96df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'g'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qsx-eksTnwW7"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import itertools\n",
        "def plot_confusion_matrix(cm, classes=['0','1'],\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "    \n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICKcJAUloYF9"
      },
      "source": [
        "### Prediction stuffs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mt5t9_5jXtqy",
        "outputId": "243b044d-8b06-458a-c79e-2e0280aec2cb"
      },
      "source": [
        "model.evaluate(test_gen, steps= len(test_data)//10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.4983346462249756\n",
            " 1/38 [..............................] - ETA: 1s - loss: 1.6485 - accuracy: 0.18750.9928512573242188\n",
            " 2/38 [>.............................] - ETA: 17s - loss: 1.7269 - accuracy: 0.09381.470564365386963\n",
            " 3/38 [=>............................] - ETA: 17s - loss: 1.7470 - accuracy: 0.10421.9372446537017822\n",
            " 4/38 [==>...........................] - ETA: 16s - loss: 1.7578 - accuracy: 0.12502.4254095554351807\n",
            " 5/38 [==>...........................] - ETA: 16s - loss: 1.7386 - accuracy: 0.12502.924988031387329\n",
            " 6/38 [===>..........................] - ETA: 15s - loss: 1.7541 - accuracy: 0.12503.3688457012176514\n",
            " 7/38 [====>.........................] - ETA: 14s - loss: 1.7612 - accuracy: 0.12503.8463621139526367\n",
            " 8/38 [=====>........................] - ETA: 14s - loss: 1.7744 - accuracy: 0.13284.310835599899292\n",
            " 9/38 [======>.......................] - ETA: 13s - loss: 1.7693 - accuracy: 0.14584.779190301895142\n",
            "10/38 [======>.......................] - ETA: 13s - loss: 1.7735 - accuracy: 0.13125.226845979690552\n",
            "11/38 [=======>......................] - ETA: 12s - loss: 1.7790 - accuracy: 0.13645.701754808425903\n",
            "12/38 [========>.....................] - ETA: 12s - loss: 1.7801 - accuracy: 0.13546.160735130310059\n",
            "13/38 [=========>....................] - ETA: 11s - loss: 1.7593 - accuracy: 0.14906.6566386222839355\n",
            "14/38 [==========>...................] - ETA: 11s - loss: 1.7694 - accuracy: 0.14297.105786561965942\n",
            "15/38 [==========>...................] - ETA: 10s - loss: 1.7704 - accuracy: 0.14177.570099830627441\n",
            "16/38 [===========>..................] - ETA: 10s - loss: 1.7671 - accuracy: 0.14848.049111127853394\n",
            "17/38 [============>.................] - ETA: 10s - loss: 1.7835 - accuracy: 0.13978.522654294967651\n",
            "18/38 [=============>................] - ETA: 9s - loss: 1.7836 - accuracy: 0.1354 9.017164468765259\n",
            "19/38 [==============>...............] - ETA: 9s - loss: 1.7819 - accuracy: 0.14149.463865995407104\n",
            "20/38 [==============>...............] - ETA: 8s - loss: 1.7780 - accuracy: 0.14069.93703031539917\n",
            "21/38 [===============>..............] - ETA: 8s - loss: 1.7719 - accuracy: 0.136910.394629955291748\n",
            "22/38 [================>.............] - ETA: 7s - loss: 1.7710 - accuracy: 0.136410.879541397094727\n",
            "23/38 [=================>............] - ETA: 7s - loss: 1.7690 - accuracy: 0.133211.337218761444092\n",
            "24/38 [=================>............] - ETA: 6s - loss: 1.7697 - accuracy: 0.130211.36965012550354\n",
            "0.4917573928833008\n",
            "26/38 [===================>..........] - ETA: 5s - loss: 1.7632 - accuracy: 0.13470.9821968078613281\n",
            "27/38 [====================>.........] - ETA: 5s - loss: 1.7648 - accuracy: 0.12951.4630372524261475\n",
            "28/38 [=====================>........] - ETA: 4s - loss: 1.7657 - accuracy: 0.12931.9266977310180664\n",
            "29/38 [=====================>........] - ETA: 4s - loss: 1.7665 - accuracy: 0.13142.425722599029541\n",
            "30/38 [======================>.......] - ETA: 3s - loss: 1.7629 - accuracy: 0.13122.9605069160461426\n",
            "31/38 [=======================>......] - ETA: 3s - loss: 1.7652 - accuracy: 0.13103.4790945053100586\n",
            "32/38 [========================>.....] - ETA: 2s - loss: 1.7665 - accuracy: 0.13083.9978344440460205\n",
            "33/38 [=========================>....] - ETA: 2s - loss: 1.7696 - accuracy: 0.13264.513097524642944\n",
            "34/38 [=========================>....] - ETA: 1s - loss: 1.7683 - accuracy: 0.13615.023863792419434\n",
            "35/38 [==========================>...] - ETA: 1s - loss: 1.7696 - accuracy: 0.13215.529641151428223\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 1.7714 - accuracy: 0.13376.045997142791748\n",
            "37/38 [============================>.] - ETA: 0s - loss: 1.7720 - accuracy: 0.13346.561016798019409\n",
            "38/38 [==============================] - 18s 476ms/step - loss: 1.7649 - accuracy: 0.1383\n",
            "7.119435787200928\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.764934778213501, 0.13827992975711823]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDQUiVnnYt5V",
        "outputId": "46b95a49-60f6-426a-fb8a-b557484326eb"
      },
      "source": [
        "model.evaluate(val_gen, steps= len(val_data)//10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "43/43 [==============================] - 28s 672ms/step - loss: 1.3743 - accuracy: 0.3628\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.3742914199829102, 0.36279070377349854]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98GNPwYnrgPx"
      },
      "source": [
        "confusion = confusion_matrix(,model.predict(val_gen))\n",
        "report = classification_report(X1,X2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mN4vwIR3piiv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf257454-45fe-427f-f797-07eff9e273f1"
      },
      "source": [
        "import pandas as pd\n",
        "pd.read_csv('/content/drive/MyDrive/winno_data/dataset.csv')['label'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "book           39\n",
              "drink          33\n",
              "computer       29\n",
              "before         26\n",
              "chair          25\n",
              "               ..\n",
              "fingerspell     4\n",
              "little bit      4\n",
              "meaning         3\n",
              "tv              3\n",
              "grey            2\n",
              "Name: label, Length: 2000, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjeJckHNjbl-"
      },
      "source": [
        "##### Models\n",
        "# x is the input value of shape \n",
        "# for grayscale image (8, 64, 64, 1)\n",
        "#(n, 8, 64, 64, 1)\n",
        "# for coloured image(8, 64,64, 3)\n",
        "# here 8 is number of frames\n",
        "# so the argument shape for CRNN will be (64, 64, 3)\n",
        "# Point to note is that (64, 64, 3) will hardly give some good results because it is very small and grayscale\n",
        "\n",
        "class CRNN(Layer):\n",
        "  def __init__(self, shape, num_classes, attention=False):\n",
        "    super(CRNN, self).__init__()\n",
        "    self.attention = attention\n",
        "    self.network = Sequential()\n",
        "    self.network.add(InputLayer(input_shape = shape))\n",
        "    self.network.add(Conv2D(32, (3,3), strides = 2, activation= 'relu'))\n",
        "    #self.network.add(Conv2D(32, (3,3), strides = 2, activation= 'relu'))\n",
        "    #self.network.add(Dropout(rate = 0.3))\n",
        "    #self.network.add(BatchNormalization())\n",
        "    self.network.add(Conv2D(64, (3,3), activation='relu'))\n",
        "    #self.network.add(Conv2D(64, (3,3), activation='relu'))\n",
        "    self.network.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    #print(self.network.output.shape)\n",
        "    #self.network.add(BatchNormalization())\n",
        "    self.network.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "    #self.network.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "    self.network.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    self.network.add(Flatten())\n",
        "    self.network.add(Dense(128, activation='relu'))\n",
        "    self.network.add(Dense(num_classes, activation='softmax'))\n",
        "    #print(self.network.output.shape)\n",
        "    self.rnn_input_shape = self.network.output.shape\n",
        "    #self.network.add(LSTM(units = 512, input_shape = self.rnn_input_shape, return_sequences=True))\n",
        "    self.rnn = LSTM(units = 512, return_sequences= True)\n",
        "    self.dense = Sequential([\n",
        "                             Flatten(),\n",
        "                             Dense(128, activation='relu'),\n",
        "                             Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    if self.attention:\n",
        "      self.attention_layer = Attention()\n",
        "\n",
        "  def call(self, x):\n",
        "    x= x[0]\n",
        "    print(\"shape:\", x.shape)\n",
        "    conv_layers_output = []\n",
        "    for i in range(x.shape[0]):\n",
        "      inp = x[:, i, :, :, :]#.reshape((1, 64, 64, 3))\n",
        "      out = self.network(inp)\n",
        "      conv_layers_output.append(out)\n",
        "    out = self.rnn(out)\n",
        "    out = out.reshape(out.shape[1:])\n",
        "    if self.attention:\n",
        "      out = self.attention_layer([out])\n",
        "      out = self.dense(out)\n",
        "    else:\n",
        "      out = self.dense(out)\n",
        "    \n",
        "    return out\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}